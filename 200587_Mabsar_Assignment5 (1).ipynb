{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had tried to summarise the research paper on Stochastic Gradient Markov Chain Monte Carlo , so please consider this too.\n",
    "\n",
    "Q1) In general the posterior distribution cannot be calculated analytically and has to be approximated. Some of the deterministic approximations , such as the laplace approximation ,vatiational Bayes , aim to approximate the posterior with a simpler tractable distirbution. these deterministic approximations are often fit using fast optimization techniques and trade-off exact posterior inference for computational efficiency. MCMC algorithms on one hand have the advantage of provising asymptotically exact posterior samples but on the other hand it comes at the expense of being computationally slow. To overcome this problem and inspired by the stochastic gradient descent(SGD) Welling and Teh proposed stochastic gradient component of the unadjusted langevin algorithm , where the gradient component of the unadjusted langevin algorithm is replaced by a stochastic approximation calculated on a subsample of the full data. A clear advantage that SGMCMC has over other subsampling-based MCMC techniques ,is that it can be applied to a broad class models.\n",
    "\n",
    "_Langevin-Based Stochastic Gradient MCMC_ \n",
    "This introduces the langevin diffusion and its discrete-time approximation as the basis for the SGMCMC. it also presents the theoretical error bounds on the posterior approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are interested in sampling from a target density œÄ(Œ∏) where the unnormalized density is of the form œÄ(Œ∏) ‚àù exp{‚àíU(Œ∏)} and defined in terms of a potential function U(Œ∏). Assuming that U(Œ∏) is continous and differnetiable everywhere(necessary conditions) the potential will be defined as a sum over data points from Bayesian analysis for big data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example if we have independent data y1, y2,...,yn then œÄ(Œ∏)‚àùp(Œ∏)‚àèf(yi|Œ∏) where p(Œ∏) is the prior density and f(yi|Œ∏) is the likelihood for the ith observation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "furthermore the langevin diffusion, defined by the stochastic differential equation:\n",
    "                                    dŒ∏(t) = -1/2 ‚àáU(Œ∏(t))dt + dBt,\n",
    "where ‚àáU(Œ∏(t)) is the drift term and Bt denotes the d-dimensional Brownian motion.This equation can be interpreted as defining the dynamics of a continous-time markov process over infinitesimally small intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are interseted in sampling form the langevin diffusion at some fixed time T, then the euler discretization will become more accurate as we decrease h: ans we can acheive any required degree if accuracy if we choose h small enough. which in itself is problemistic as it is difficult to practice when h is small enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its important to approximate MCMC using langevin diffusion as the langevin diffusion has œÄ as its stationary distibution, it is natural to consider this stochastic process as a basis for an MCMC algorithm. However , for general œÄ(Œ∏) the langevin dynamics are intractable and in practice people often resort to euler approximations.This is most commonly seen with the Metropolis-adjusted Langevin algorithm, or MALA.This algorithm uses the Euler approximation over an approximately chosen time-interval, h, to define the proposal distribution of a standard Metropolis‚ÄìHastings algorithm. The simulated value is then either accepted or rejected based on the Metropolis‚ÄìHastings acceptance probability. MALA is generally large, resulting in a poor Euler approximation to the Langevin dynamics‚Äîand so ULA requires a smaller step size, and potentially many more iterations. One advantage that ULA has is that its performance is more robust to poorinitializations; by comparison a well-tuned MALA algorithm\n",
    "often has a high rejection probability if initialized in the tail of the posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computational bottleneck for ULA is in calculating ‚àáU(Œ∏), particularly if we have a large sample size, N, as U(Œ∏) =‚àëUi(Œ∏). The simplest implementation is to choose n<<N and estimate ‚àáU(Œ∏) with  ‚àáU(ùúÉ)=ùëÅ/ùëõ‚àëùëñ=ùëÜùëõ‚àáUi(ùúÉ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage of SGLD is that, if n<<N, the per-iteration cost of the algorithm can be much smaller than either MALA\n",
    "or ULA. For large data applications, SGLD has been empirically shown to perform better than standard MCMC when there is\n",
    "a fixed computational budget.The SGLD algorithm is closely related to SGD,an efficient algorithm for finding local maxima\n",
    "of a function. The only difference is the inclusion of the additive Gaussian noise at each iteration of SGLD. Without the noise, but with a suitably decreasing step size, SGD would converge to a local maxima of the density œÄ(Œ∏).This strong link between SGLD and SGD, and the good performance the SGD often has for prediction, may also explain why the former performs well when compared to exact MCMC methods in terms of prediction accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Approximating MCMC Using the Langevin diffusion we move onto Estimating the gradient . A key part of SGLD is replacing the true gradient with an estimate. The more accurate this estimator is, the better we would expect SGLD to perform, and thus it is natural to consider alternatives to the simple estimator. One way of reducing the variance of Monte Carlo estimator is to use control variates , which in our setting involves choosing a set of simple functions Ui , i = 1,....N, whose sum \n",
    "$\\sum\\limits_{i=1}^{N}  ‚àáui(\\theta) $ is Known for any $\\theta$. As"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\sum\\limits_{i=1}^{N}‚àáU_{i}(\\theta) = \\sum\\limits_{i=1}^{N} u_{i}(\\theta) + \\sum\\limits_{i=1}^{N}(‚àáU_{i}(\\theta) - u_{i}(\\theta)) $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing such an estimator involves an up-front of cost of finding a suitable ÀÜŒ∏ and calculating, storing and summing\n",
    "‚àáUi(ÀÜŒ∏) for i = 1, ... , N. Of these, the main cost is finding a suitable ÀÜŒ∏. Though we can then use ÀÜŒ∏ as a starting value for\n",
    "the SGLD algorithm, replacing Œ∏ 0 with ÀÜŒ∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have considered SGMCMC based on approximating the dynamics of the Langevin diffusion. However, we can write down other diffusion processes that have œÄ as their stationary distribution, and use similar ideas to approximately simulate from one of these. A general approach to doing this was suggested by Ma, Chen, and Fox (2015) and leads to a much wider class of SGMCMC algorithms, including stochastic gradient versions of popular MCMC algorithms such as Hamiltonian Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class of diffusions we will consider may include a set of auxiliary variables. As such, we let Œ∂ be a general state, with the assumption that this state contains Œ∏. For example, for the Langevin diffusion Œ∂ = Œ∏; but we could mimic Hamiltonian MCMC and introduce an auxiliary velocity component, œÅ, in which case Œ∂ = (Œ∏, œÅ). We start by considering a general stochastic differential equation for Œ∂ ,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ d\\zeta = 1/2b(\\zeta)dt + \\sqrt{D(\\zeta)}dB_{t} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where ùëè(ùúÅ) is the drift component ,ùê∑(ùúÅ) is a positive semidefinite diffusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The closest link with the dynamics used in Hamiltonian MCMC is when D(Œ∂ ) is set to be the zero-matrix. However, Chen, Fox, and Guestrinshowed that this leads to an unstable process that diverges as a result of the accumulation of noise in the estimate of the gradient; a property linked to the fact that D(Œ∂ ) ‚àí b(Œ∂ ) is not positive semidefinite for any h. The choice of D(Œ∂ ) given in Table 1 avoids this problem, with the resulting stochastic differential equation being the so-called under-damped Langevin diffusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above snippets try and summarise the working of SGMCMC algorithms. These algorithms utilize data subsampling to significantly reduce the computational cost of the MCMC and provide parameter inference at levels of accuracy that are comparable to traditional MCMC algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2) Research Paper - Efficient Bernoulli factory MCMC for intractable posteriors\n",
    " $\\\\$\n",
    "The Barker Algorithmn  ensures the stationarity of $\\pi$ and the update step is defined as:-$\\\\$\n",
    "$$ \\alpha_B(x,y)=\\frac{\\pi(y)q(y,x)}{\\pi(x)q(x,y)+\\pi(y)q(y,x)} \\\\$$\n",
    "$$\\implies \\alpha_B(x,y)=\\frac{\\pi\\prime(x)q(x,y)}{\\pi\\prime(x)q(x,y)+\\pi\\prime(y)q(y,x)} $$\n",
    "\n",
    "However, it is not possible to calculate $\\alpha_B$ everytime. We can get over this problem by using Bernouli factory to obtain events of probability $\\alpha_B(x_m,y)$ without evaluting it.\n",
    "\n",
    "So, algorithmn for Barker's will be :\n",
    "\n",
    "1. Draw $y\\sim q(x_m,dy)$\n",
    "2. Draw $A\\sim Bern(\\alpha_B(x_m,y))$\n",
    "3. If A=1 then\n",
    "4. $x_{m+1}=y \\\\$\n",
    "5.Else $\\\\$\n",
    "6.$x_{m+1}=x_m$    \n",
    "\n",
    "Now, the goal is to find events which occur with probility h(p). We can use the following bernouli factory to sample events with probability $\\alpha_B(x,y)$ Let $\\\\$\n",
    "$$\\pi(x)q(x,y)=c_xp_x$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here $c_x$ is the local bound i.e:$\\\\$\n",
    "$$\\pi(x)q(x,y)\\le c_x\\space so \\space set\\space p_x=\\frac{\\pi(x)q(x,y)}{c_x}\\\\$$\n",
    "We can use \n",
    "$$h(p_x,p_y)=\\frac{c_yp_y}{c_xp_x+c_yp_y}=\\alpha_B(x,y) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know the number of loops before stopping forms a Geometric Series with ratio $\\frac{c_xp_x+c_yp_y}{c_x+c_y}.\\\\$\n",
    "The mean execution time is 1/r or $s_1=\\frac{c_x+c_y}{c_xp_x+c_yp_y}\\\\$\n",
    "\n",
    "So, the running time of algorithmn is dependent on $c_x\\space and \\space c_y$, which in turn depend on bound of the distribution. If bound is loose then it yields a large mean time.\n",
    "\n",
    "So this section talks about a new approach to update step without evaluting the acceptance probability, using Bernouli factories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 3:-PortKey Barker's Method:-\n",
    "The inefficiency in implemneting the Bernouli factory is from the inefficiency of the two-coin algorithm. So , to improve upon this we can introduce new acceptance ratio for which the Bernouli factory method is efficent. For a proposal density q(x,y) , consider \n",
    "$$\\alpha(x,y)=\\frac{\\pi(y)q(y,x)}{\\pi(x)q(x,y)+\\pi(y)q(y,x)+d(x,y)}$$ \n",
    "where $d(x,y) \\ge 0 \\\\$\n",
    "Now as we want the $\\pi$ to be invariant so $\\pi$ must be reversible markov chain. So, it is possible if and only if \n",
    "$$\\pi(y)q(y,x)\\alpha(y,x)=\\pi(x)q(x,y)\\alpha(x,y)\\\\$$\n",
    "Now let d(x,y)=d(y,x) So:-\n",
    "$$\\pi(y)q(y,x)\\alpha(y,x)=\\frac{\\pi(y)q(y,x)\\pi(x)q(x,y)}{\\pi(x)q(x,y)+\\pi(y)q(y,x)+d(x,y)}=\\pi(x)q(x,y)\\alpha(x,y) $$\n",
    "Hence $\\pi$ is reversible.\n",
    "\n",
    "Now, by Peskun‚Äôs ordering, Barker‚Äôs method is more efficient. However, for a particular choice of d(x,y) we present a Bernoulli factory that provides significant computational gain.\n",
    "For a user-choosen $0<\\beta \\le 1$ we consider the following acceptance probability:-\n",
    "$$\\alpha_{\\beta}(x,y)=\\frac{\\pi(y)q(y,x)}{\\pi(x)q(x,y)+\\pi(y)q(y,x)+\\frac{1-\\beta}{\\beta}(c_x+c_y)} $$\n",
    "where c_x and c_y is given as previously.$\\\\$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\beta \\approx 1 $ so that d(x,y) is small. To yield $\\alpha_{\\beta}(x,y)$ we modify the two-coin algorithm via, what we call a portkey method. Our portkey two-coin algorithm introduces a first step in the two-coin algorithm that allows immediate rejections with probability 1 ‚àí Œ≤. So avoids running large number of loops witnessed in the previous algorithmn.\n",
    "\n",
    "Now again it will follow a Geometric series with ratio r=$\\frac{c_yp_y}{c_xp_x+c_yp_y+\\frac{1-\\beta}{\\beta}(c_x+c_y)}$, hence mean running time is \n",
    "$$s_{\\beta}=(1-\\beta)+\\beta\\frac{c_yp_y+c_xp_x}{c_x+c_y} $$\n",
    "So the ratio of the two algorithmn is\n",
    "$$\\frac{s_{\\beta}}{s_1}=(1-\\beta)\\frac{c_x+c_y}{c_yp_y+c_xp_y}+\\beta $$\n",
    "It is clearly greater than 1, so our new algorithmn takes lesser time.\n",
    "\n",
    "But this computational  efficiency comes at the price of statistical efficiency.\n",
    "Let $P_B \\space and \\space P_{\\beta}$ denote the Markov operators for Barker's and Portkey algorithms respectively.\n",
    "Also, let $\\bar g_n$ denote the Monte Carlo Estimator of $\\int_{}^{} g\\pi(dx) $ using kernel P. \n",
    "Let var(g,P) denote $\\lim_{n \\to \\infty}nVar(\\bar g_n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for $0<\\beta \\le 1, \\alpha_{\\beta}(x,y) \\le \\beta \\alpha_B(x,y) $ which results in \n",
    "$$ var(g,P_B)\\le var(g,P_{\\beta})+(\\beta-1)Var_{\\pi}(\\bar g_n)\n",
    "Another important result that follows is $0<\\beta \\le 1$ if there exists $\\delta>0$ such that $p_x>\\delta$ then\n",
    "$$\\alpha_B(x,y) \\le (1+\\frac{1-\\beta}{\\delta\\beta}).\\alpha_{\\beta}(x,y) $$\n",
    " Which leds to\n",
    "$$var(g,P_{\\beta}) \\le (1+\\frac{1-\\beta}{\\beta})var(g,P_B)+\\frac{1-\\beta}{\\delta\\beta}var_{\\pi}(g) $$\n",
    "So from the above results we can conclude that when $p_x\\space or \\space p_y$ is small, $\\beta$ should be set large, specifically $1-\\delta$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
